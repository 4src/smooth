![](https://img.shields.io/badge/tests-passing-green)
![](https://img.shields.io/badge/Lua-2C2D72?logo=lua&logoColor=white&style=plastic)
![](https://img.shields.io/badge/purpose-xai,_optimization-blue)
![](https://img.shields.io/badge/platform-mac,_linux-orange)
[![](https://img.shields.io/badge/license-BSD2-yellow)](LICENSE.md)
          
[home](/README.md) :: [make](/docs/make.md)

# Optimization

Life is walking around, guessing how makyou might improve things.

Think of an ant walking around a landscape of possibilties:


You can't drop you hook everywhere. So you got think first about where you might get best resilts.

To say that abother way, you are walking around two spaces
- the choices you can make (the indepedent variables, the inputs, the observables and controllables)
- the rewards you can gain (the depdent variables, the outputs, the goals)


![](/etc/img/spaces.png)

The Pareto frontier all the points in y-space that are can't be changed without losing something.


To say that another way, optimization is like trying to learn a function that connects _what we can do_ to _what we want to achieve_

$$y=f(x)$$

And life is walking around $x$, hoping we can get good $y$ (but really, we have very little $f$-ing idea what is going on).

# Semi-Supervised Learning